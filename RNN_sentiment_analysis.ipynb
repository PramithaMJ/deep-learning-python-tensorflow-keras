{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":879,"referenced_widgets":["d04ee22e3dd74855ba9cb9f9f8fd5d21","a5b408593f8942ebb9bc553058050ee9","40a70d56aa304efa92a2537fb9be566a","b9c29c89fdde4c34b4c597e4cba2ad6f","eb8d970436a5402c8d3906836ea3f188","054a4e60c84d47c790b75385ac52c84f","ae5b3c1f48fc46f8ac8ab9d91cd881d0","9395a6c4718e4364b5904d091b5b6e96","f45d9778f8d64787a20375e65839461c","6ae8d5b4735548c0b0a0970c44854b6c","f162ea152e664685b45e655668c293ac","880413b6c21d477e917b8aae3fd7b425","17d4785f00ba435081d74cde861a8911","9f291b419fa946da94ac5dd3440de28c","b213646a26004ad785aa9e7b48f32b6e","483b0e25e1a14784966be817c8222921","bdf6a33ca04646408edcb1927d8c5d36","029a48b6f65743408ba7a04d333a2347","ba7f592fa35e463c943dbf79a1e4f7bb","3a600ad01cb4490794bc98c39adb753f","60a5e55df53c48c6b7d92e93f971072b","8bade6c681264364b79ac4c3ced808dd"]},"id":"gzLr52UfKBHp","executionInfo":{"status":"ok","timestamp":1739463655210,"user_tz":-330,"elapsed":125272,"user":{"displayName":"P.A.D. Shehan Nilmantha Wijesekara","userId":"02692999607457084522"}},"outputId":"efe857a6-836e-4942-e0fd-7c5ac9c623e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d04ee22e3dd74855ba9cb9f9f8fd5d21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/250 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"880413b6c21d477e917b8aae3fd7b425"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/5 | Loss: 0.7001 | Train Accuracy: 0.5050\n","Epoch 2/5 | Loss: 0.6991 | Train Accuracy: 0.5190\n","Epoch 3/5 | Loss: 0.6816 | Train Accuracy: 0.5490\n","Epoch 4/5 | Loss: 0.6657 | Train Accuracy: 0.5520\n","Epoch 5/5 | Loss: 0.6377 | Train Accuracy: 0.5740\n","Test Accuracy: 0.5080\n","Sample Sentence: like \" the blair witch project \" before it, \" hatchet \" has garnered its own fair share of publicity from the bottom - on - up ( as an avid reader of fangoria magazine, the full - page ads are hard to miss ) ; even after its middling theatrical run, the film is bound to subsist solely on the hype surrounding it, and will probably turn into a cult item at some point. with a myspace url and a mighty ( if puzzlingly subjective ) promise of preserving so - called \" old school american horror, \" \" hatchet \" will draw a lot of curiosity seekers with its dvd release ( where that claim is emblazoned on the disc itself ). perhaps it was the large - print blurb from ain ' t it cool news on the ads that caused me to approach the film with some trepidation ( it seems that harry knowles and his minions will approve of any film for vip passes and free food ), but \" hatchet \" makes me question what writer - director adam green ' s idea of \" old school american horror \" really is : based on the evidence here, it means the insipid, late - ' 80s rip - offs of \" friday the 13th \" and \" deliverance. \" the characters are obnoxious stereotypes ( black chris tucker type, survivalist chick, topless bimbos, requisite old couple, asian tour guide ) whose interactions are marred by painful, trying - to - be - hip dialogues and mostly obvious stabs at humor ( not quite as bad as \" cabin fever, \" but still ) ; the script has too much padding ( the \" rustling bush \" scene, for example ), and \" hatchet \" winds up as typical as any postmodern slasher of the last decade, with its only distinguishing trait an expertly - calculated hype machine. i ' ll give it some faint praise for the gore - - if you can wade through the padding in between kills, the red vino is definitely a thing of wonder, and the only real reason to watch this.\n","Predicted Sentiment: Negative\n"]}],"source":["!pip install datasets transformers\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from datasets import load_dataset\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","# 2. Define the RNN model\n","class RNNSentiment(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n","        super().__init__()\n","\n","        # Embedding layer\n","         # Embedding layer converts input indices into dense vectors of fixed size\n","        # `input_dim`: size of vocabulary (number of unique tokens in the dataset)\n","        # `embedding_dim`: dimensionality of the embedding space (length of each vector representation)\n","\n","        self.embedding = nn.Embedding(input_dim, embedding_dim)\n","\n","        # RNN layer\n","        # RNN layer processes the embedded text sequences\n","        # `embedding_dim`: input size for the RNN (same as embedding vector size)\n","        # `hidden_dim`: number of hidden units in the RNN\n","        # `num_layers`: number of stacked RNN layers\n","        # `dropout`: dropout rate to apply between RNN layers to prevent overfitting\n","        # `batch_first=True`: ensures the input/output shape is (batch_size, seq_len, features)\n","        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n","\n","        # Fully connected layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","        # Dropout layer\n","        self.dropout = nn.Dropout(dropout)\n","\n","    # The forward method defines the computation graph for the model\n","    def forward(self, text):\n","        # Pass the input through embedding layer\n","        embedded = self.embedding(text)\n","\n","        # Pass the embedded input through RNN\n","        # `rnn_out`: the hidden states for each time step in the sequence\n","        # `_`: we don't need the RNN hidden states across layers, so we discard them\n","        rnn_out, _ = self.rnn(embedded)\n","\n","        #The variable rnn_out is the output of the RNN layer in the model, and it has the shape (batch_size, seq_len, hidden_dim).\n","        #The hidden_dim dimension represents the number of features in the RNN's hidden state at each time step.\n","        # Use the output from the last time step\n","        # We use the output from the last time step of the RNN for classification\n","        # The last time step contains information about the entire sequence (after processing all tokens)\n","\n","        last_hidden = rnn_out[:, -1, :]\n","\n","        # Apply dropout\n","        last_hidden = self.dropout(last_hidden)\n","\n","        # Output layer\n","        output = self.fc(last_hidden)\n","        return output\n","\n","# 3. Set up hyperparameters\n","embedding_dim = 100\n","hidden_dim = 128\n","output_dim = 1  # Binary classification\n","n_layers = 2\n","dropout = 0.2\n","batch_size = 64\n","epochs = 5\n","learning_rate = 0.001\n","\n","# 4. Load the IMDb dataset using Hugging Face\n","dataset = load_dataset('imdb')\n","\n","# Tokenizer\n","# Importing the AutoTokenizer from the transformers library\n","# The AutoTokenizer class is a generic class that can load the tokenizer for any pre-trained model\n","from transformers import AutoTokenizer\n","\n","# Load the pre-trained tokenizer for the BERT (Bidirectional Encoder Representations from Transformers) model (uncased version)\n","# This will handle tokenization (i.e., converting text to token IDs) for any text input.\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokenize the data\n","# Function to tokenize input text data\n","# This function takes in a dictionary of examples (typically with a 'text' field) and tokenizes them\n","def tokenize_function(examples):\n","    # Tokenizes the text using the pre-loaded tokenizer.\n","    # `padding='max_length'` ensures all sequences are padded to the maximum length of the model.\n","    # `truncation=True` ensures that texts longer than the model's input size are truncated.\n","    return tokenizer(examples['text'], padding='max_length', truncation=True)\n","\n","# Take a random sample from the train and test sets\n","# Select a random sample from the training dataset and apply tokenization\n","# The training data is shuffled with a fixed seed (42) for reproducibility\n","# Then, a subset (4% of the total training set) is selected to work with\n","train_data = dataset['train'].shuffle(seed=42).select([i for i in range(int(0.04 * len(dataset['train'])))]).map(tokenize_function, batched=True)\n","\n","# Select a random sample from the test dataset and apply tokenization\n","# Similar to the training set, the test data is shuffled with a fixed seed\n","# A smaller subset (1% of the total test set) is selected for testing\n","test_data = dataset['test'].shuffle(seed=42).select([i for i in range(int(0.01 * len(dataset['test'])))]).map(tokenize_function, batched=True)\n","\n","# 5. Create DataLoader for batching\n","# Convert the tokenized train data into a format suitable for PyTorch training\n","# `input_ids` are the token IDs, `attention_mask` is a mask that tells the model which tokens to pay attention to (1 for real tokens, 0 for padding)\n","# `label` is the target label for each input example\n","\n","# Convert the train data into a PyTorch TensorDataset for easy batching\n","train_dataset = torch.utils.data.TensorDataset(\n","    torch.tensor(train_data['input_ids']),\n","    torch.tensor(train_data['attention_mask']),\n","    torch.tensor(train_data['label'])\n",")\n","\n","test_dataset = torch.utils.data.TensorDataset(\n","    torch.tensor(test_data['input_ids']),\n","    torch.tensor(test_data['attention_mask']),\n","    torch.tensor(test_data['label'])\n",")\n","\n","#  Create DataLoaders for efficient batching and shuffling\n","# `train_loader` will iterate over `train_dataset` in batches of `batch_size` and shuffle the data for randomness\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","# 6. Initialize the model\n","# The input dimension is set to the vocabulary size of the tokenizer (BERT vocabulary)\n","input_dim = tokenizer.vocab_size\n","# Instantiate the sentiment analysis model using an RNN architecture\n","# The model takes `input_dim` (size of the vocabulary), `embedding_dim` (size of word embeddings),\n","# `hidden_dim` (number of hidden units in RNN), `output_dim` (number of output classes),\n","# `n_layers` (number of stacked RNN layers), and `dropout` (dropout rate to prevent overfitting)\n","model = RNNSentiment(input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout)\n","\n","# 7. Define loss function and optimizer\n","# Binary Cross Entropy with Logits Loss is used because this is a binary classification problem. Logits refer to the raw,\n","#unnormalized output values produced by the last layer of a neural network before any activation function (like sigmoid or softmax) is applied.\n","# This loss function expects raw logits as inputs and applies a sigmoid activation internally\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Adam optimizer is used to update model parameters during training\n","# `learning_rate` defines the step size for updates to minimize loss\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 8. Train the model\n","# Loop through multiple epochs (full passes through the training dataset)\n","for epoch in range(epochs):\n","    model.train() # Set the model to training mode\n","    total_loss = 0 # Accumulate total loss for the epoch\n","    correct_preds = 0 # Track correct predictions for accuracy calculation\n","    total_preds = 0 # Track total number of predictions\n","    for input_ids, attention_mask, labels in train_loader:\n","        optimizer.zero_grad() # Reset gradients before each batch\n","\n","        # Forward pass: pass tokenized input text through the model\n","        output = model(input_ids) # Output is raw logits (before applying sigmoid)\n","\n","        # Compute loss and backpropagate\n","        # Compute the loss between predicted logits and true labels\n","        # `squeeze(1)` removes extra dimension to match expected shape\n","        loss = criterion(output.squeeze(1), labels.float())\n","\n","        # Backpropagation: compute gradients\n","        loss.backward()\n","\n","        # Update model parameters using optimizer\n","        optimizer.step()\n","\n","        # Accumulate total loss\n","        total_loss += loss.item()\n","\n","        # Compute accuracy\n","        preds = torch.round(torch.sigmoid(output))# Apply sigmoid and round to get binary predictions (0 or 1)\n","        correct_preds += (preds.squeeze(1) == labels).sum().item() # Count correct predictions\n","        total_preds += labels.size(0) # Keep track of total predictions\n","\n","    train_accuracy = correct_preds / total_preds\n","    # Print epoch-wise training loss and accuracy\n","    print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(train_loader):.4f} | Train Accuracy: {train_accuracy:.4f}\")\n","\n","# 9. Evaluate the model\n","# Set the model to evaluation mode\n","# In evaluation mode, layers like dropout and batch normalization behave differently from training mode.\n","# This ensures that the model makes stable predictions without any random noise introduced by dropout.\n","\n","model.eval()\n","correct_preds = 0\n","total_preds = 0\n","\n","# Disable gradient calculation to reduce memory usage and computation during evaluation\n","# `torch.no_grad()` temporarily disables gradient calculation, which speeds up inference and reduces memory usage.\n","# This is because gradients are not needed for the forward pass when evaluating the model.\n","with torch.no_grad():\n","    # Evaluation code (e.g., loop through test dataset and make predictions)\n","    for input_ids, attention_mask, labels in test_loader:\n","        output = model(input_ids)\n","        preds = torch.round(torch.sigmoid(output))\n","        correct_preds += (preds.squeeze(1) == labels).sum().item()\n","        total_preds += labels.size(0)\n","\n","test_accuracy = correct_preds / total_preds\n","print(f\"Test Accuracy: {test_accuracy:.4f}\")\n","\n","\n","# After evaluating the model, print a sentence from the dataset with its predicted sentiment\n","model.eval()\n","with torch.no_grad():\n","    # Select a random sample from the test dataset\n","    idx = np.random.randint(0, len(test_dataset))  # Random index\n","    input_ids, attention_mask, label = test_dataset[idx]\n","\n","    # Convert to a batch\n","    input_ids = input_ids.unsqueeze(0)  # Add batch dimension\n","    attention_mask = attention_mask.unsqueeze(0)  # Add batch dimension\n","\n","    # Get the model's prediction\n","    output = model(input_ids)\n","    prediction = torch.round(torch.sigmoid(output)).squeeze(1).item()  # Get predicted sentiment (0 or 1)\n","\n","    # Map the prediction to a sentiment string\n","    sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n","\n","    # Get the original sentence\n","    sentence = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n","\n","    # Print the sentence and the predicted sentiment\n","    print(f\"Sample Sentence: {sentence}\")\n","    print(f\"Predicted Sentiment: {sentiment}\")\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMhTzSqLeuY1q/ytTDdqS2O"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d04ee22e3dd74855ba9cb9f9f8fd5d21":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5b408593f8942ebb9bc553058050ee9","IPY_MODEL_40a70d56aa304efa92a2537fb9be566a","IPY_MODEL_b9c29c89fdde4c34b4c597e4cba2ad6f"],"layout":"IPY_MODEL_eb8d970436a5402c8d3906836ea3f188"}},"a5b408593f8942ebb9bc553058050ee9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_054a4e60c84d47c790b75385ac52c84f","placeholder":"​","style":"IPY_MODEL_ae5b3c1f48fc46f8ac8ab9d91cd881d0","value":"Map: 100%"}},"40a70d56aa304efa92a2537fb9be566a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9395a6c4718e4364b5904d091b5b6e96","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f45d9778f8d64787a20375e65839461c","value":1000}},"b9c29c89fdde4c34b4c597e4cba2ad6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ae8d5b4735548c0b0a0970c44854b6c","placeholder":"​","style":"IPY_MODEL_f162ea152e664685b45e655668c293ac","value":" 1000/1000 [00:01&lt;00:00, 559.94 examples/s]"}},"eb8d970436a5402c8d3906836ea3f188":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"054a4e60c84d47c790b75385ac52c84f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae5b3c1f48fc46f8ac8ab9d91cd881d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9395a6c4718e4364b5904d091b5b6e96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f45d9778f8d64787a20375e65839461c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ae8d5b4735548c0b0a0970c44854b6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f162ea152e664685b45e655668c293ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"880413b6c21d477e917b8aae3fd7b425":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17d4785f00ba435081d74cde861a8911","IPY_MODEL_9f291b419fa946da94ac5dd3440de28c","IPY_MODEL_b213646a26004ad785aa9e7b48f32b6e"],"layout":"IPY_MODEL_483b0e25e1a14784966be817c8222921"}},"17d4785f00ba435081d74cde861a8911":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdf6a33ca04646408edcb1927d8c5d36","placeholder":"​","style":"IPY_MODEL_029a48b6f65743408ba7a04d333a2347","value":"Map: 100%"}},"9f291b419fa946da94ac5dd3440de28c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba7f592fa35e463c943dbf79a1e4f7bb","max":250,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a600ad01cb4490794bc98c39adb753f","value":250}},"b213646a26004ad785aa9e7b48f32b6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60a5e55df53c48c6b7d92e93f971072b","placeholder":"​","style":"IPY_MODEL_8bade6c681264364b79ac4c3ced808dd","value":" 250/250 [00:00&lt;00:00, 667.82 examples/s]"}},"483b0e25e1a14784966be817c8222921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdf6a33ca04646408edcb1927d8c5d36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"029a48b6f65743408ba7a04d333a2347":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba7f592fa35e463c943dbf79a1e4f7bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a600ad01cb4490794bc98c39adb753f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60a5e55df53c48c6b7d92e93f971072b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bade6c681264364b79ac4c3ced808dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}